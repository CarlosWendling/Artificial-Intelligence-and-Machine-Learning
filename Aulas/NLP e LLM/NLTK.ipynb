{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vr_hzB5b_JBa"
      },
      "outputs": [],
      "source": [
        "# ntlk é uma das bibliotecas mais tradicionais para NLP\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer, SnowballStemmer, LancasterStemmer\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.tag import pos_tag, pos_tag_sents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string"
      ],
      "metadata": {
        "id": "fmA0W92XEscC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download de modelos específicos para a prática\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"tagsets\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n",
        "nltk.download(\"maxent_ne_chunker\")\n",
        "nltk.download(\"words\")"
      ],
      "metadata": {
        "id": "cw98-CSRAvJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Corpus\n",
        "Texto = '''Nós somos feitos de poeira de estrelas. Nós somos uma maneira de o\n",
        "cosmos se autoconhecer. A imaginação nos leva a mundos que nunca\n",
        "sequer existiram. Mas sem ela não vamos a lugar algum.  '''\n",
        "print(Texto)"
      ],
      "metadata": {
        "id": "bsGl7l3PBU1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TOKENIZATION\n",
        "sentencas = sent_tokenize(Texto, language=\"portuguese\")\n",
        "print(type(sentencas))\n",
        "print(sentencas) # cada sentença é armazenada em um espaço de uma lista"
      ],
      "metadata": {
        "id": "pAg_3sxsBybG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(sentencas))"
      ],
      "metadata": {
        "id": "vHOVbJzuCT9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(Texto, language=\"portuguese\")\n",
        "print(tokens) # agora todos elementos da sentença são separados e postos em uma única lista"
      ],
      "metadata": {
        "id": "YvsNp2bTCiTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STOPWORDS -> palavras que não tem valor semântico\n",
        "stops = stopwords.words(\"portuguese\")\n",
        "print(stops)"
      ],
      "metadata": {
        "id": "cbd75FbUCsbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removendo as stopwords para que não prejudique o modelo\n",
        "palavras_sem_stopwords = [p for p in tokens if p not in stops]\n",
        "print(palavras_sem_stopwords)"
      ],
      "metadata": {
        "id": "ptGVeyvGDV8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# diferença da remoção das stopwords\n",
        "print(len(tokens))\n",
        "print(len(palavras_sem_stopwords))"
      ],
      "metadata": {
        "id": "6MACSWNSEHcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# conjunto que contém as pontuações\n",
        "print(string.punctuation)"
      ],
      "metadata": {
        "id": "846GbCw8ES4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removendo pontuação\n",
        "palavras_sem_pontuacao = [p for p in palavras_sem_stopwords if p not in string.punctuation]\n",
        "print(palavras_sem_pontuacao)"
      ],
      "metadata": {
        "id": "TK8EFSlRE101"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# consultas a repetição de palavras -> retorna um dicionário em ordem decrescente\n",
        "frequencia = nltk.FreqDist(palavras_sem_pontuacao)\n",
        "frequencia"
      ],
      "metadata": {
        "id": "UaLHLuMlFE12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# consultar as palavras mais comuns\n",
        "mais_comuns = frequencia.most_common(2)\n",
        "mais_comuns"
      ],
      "metadata": {
        "id": "2qVlqrQcFhNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# técnicas para redução das palavras (usando stemer, que é mais simples que lemmatizing)\n",
        "stemmer = PorterStemmer()\n",
        "stem1 = [stemmer.stem(word) for word in palavras_sem_pontuacao]\n",
        "print(stem1)"
      ],
      "metadata": {
        "id": "Net3U4hjGNfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer2 = SnowballStemmer(\"portuguese\")\n",
        "stem2 = [stemmer2.stem(word) for word in palavras_sem_pontuacao]\n",
        "print(stem2)"
      ],
      "metadata": {
        "id": "a75BM7j4Jabv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer3 = LancasterStemmer()\n",
        "stem3 = [stemmer3.stem(word) for word in palavras_sem_pontuacao]\n",
        "print(stem3)"
      ],
      "metadata": {
        "id": "piaDCluHJsuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lista de POS Tagging para entender as tags atribuídas às palavras\n",
        "nltk.help.upenn_tagset()"
      ],
      "metadata": {
        "id": "tuWX67xyKIl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# aplicando o POS Taggin\n",
        "pos = nltk.pos_tag(palavras_sem_pontuacao)\n",
        "print(pos)"
      ],
      "metadata": {
        "id": "oA_edkdDK33i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LEMMATIZING\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "resultado = [lemmatizer.lemmatize(palavra) for palavra in palavras_sem_pontuacao]\n",
        "print(resultado)"
      ],
      "metadata": {
        "id": "7mqOUwgMLHCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ENTIDADES NOMEADAS -> reconhecimento de famosos, por ex\n",
        "texto_en = \"Barak Obama foi um presidente dos EUA\"\n",
        "token3 = word_tokenize(texto_en)\n",
        "tags = pos_tag(token3)\n",
        "en = nltk.ne_chunk(tags)\n",
        "print(en)"
      ],
      "metadata": {
        "id": "JoMRHkw0L-m0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}